2021-03-03 19:11:57 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: Day029)
2021-03-03 19:11:57 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.3.1, Platform Windows-10-10.0.19041-SP0
2021-03-03 19:11:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-03-03 19:11:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Day029',
 'LOG_FILE': './output/ptt.log',
 'NEWSPIDER_MODULE': 'Day029.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['Day029.spiders']}
2021-03-03 19:11:57 [scrapy.extensions.telnet] INFO: Telnet Password: 3f437295e95d074c
2021-03-03 19:11:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-03-03 19:11:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-03 19:11:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-03 19:11:57 [scrapy.middleware] INFO: Enabled item pipelines:
['Day029.pipelines.Day029Pipeline']
2021-03-03 19:11:57 [scrapy.core.engine] INFO: Spider opened
2021-03-03 19:11:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-03 19:11:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-03-03 19:11:57 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://www.ptt.cc/bbs/DataScience/index.html> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2021-03-03 19:11:58 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ptt.cc/robots.txt> (referer: None)
2021-03-03 19:11:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ptt.cc/bbs/DataScience/index.html> (referer: None)
2021-03-03 19:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ptt.cc/bbs/DataScience/M.1612527945.A.1FE.html> (referer: https://www.ptt.cc/bbs/DataScience/index.html)
2021-03-03 19:11:59 [scrapy.core.scraper] ERROR: Error processing {'article_author': 'jack1218 (赤城我老婆)',
 'article_content': '\n'
                    '\n'
                    '如題\n'
                    '最近在學NLP 所以爬了ptt八卦版的問卦\n'
                    '準備做推噓文的預測\n'
                    '不過自己玩有點無聊 所以把dataset整理好放到kaggle上 開個小競賽\n'
                    '有興趣的人可以一起玩玩看\n'
                    '期限是一個月\n'
                    '\n'
                    'https://www.kaggle.com/c/ptt-gossiping-push-down-predict/',
 'article_date': 'Fri Feb  5 20:25:43 2021',
 'article_id': 'M.1612527945.A.1FE',
 'article_title': '[情報] 新手向kaggle自辦競賽 ptt推噓文預測',
 'ip': '223.137.94.234',
 'message_count': 29,
 'messages': ' 推推=====分隔線===== 有趣....=====分隔線===== XD=====分隔線===== have '
             'fun!=====分隔線===== 還在念博士時有做過用PTT文章預測投票票數的，當時結果很=====分隔線===== '
             '神奇地好。不過預測推噓文，直覺上要好會需要用手段補充外=====分隔線===== 在背景知識=====分隔線===== '
             '總之這題目確實挺有趣的=====分隔線===== '
             '另外，其實我認為發文作者是其中一個鑑別力很強的feature=====分隔線===== '
             '，這邊沒有提供XD=====分隔線===== 顏色正確就推爆=====分隔線===== 蠻有趣的=====分隔線===== '
             '光從發文作者就可以判斷的case應該要被當outliers吧=====分隔線===== '
             '提供作者有個重點是可以查詢上站次數跟文章次數，而這兩項=====分隔線===== 我認為是很重要的特徵=====分隔線===== '
             '舉一個已經有實用經驗的例子，Youtube的自動判斷機制在接=====分隔線===== '
             '到影片舉報時，他們研究發現最有辨別能力的特徵就是發該影=====分隔線===== '
             '片的使用者是否是很新的帳號，若是則大機率真的是問題影片=====分隔線===== 而針對PTT，我個人的觀察是去看 '
             '文章篇數/上站次數 這個比=====分隔線===== 值，對於文章是不是廢文的機率也有高辨識度=====分隔線===== '
             '若這個比值達到1以上，越高就越可能是廢文=====分隔線===== '
             '但如果比值大約在0.5前後，則相對用心發文的機率較高=====分隔線===== '
             '比值若很接近0（也就是發文很少上站很多），又會反過來變=====分隔線===== '
             '成內容不足的機率提升，但狀況相對比值高於1的輕微=====分隔線===== '
             '另外取得作者還有一項判斷依據，就是有些人可能在特定版面=====分隔線===== '
             '容易被噓但在別的特定版面容易被推，先不提所謂政治傾向，=====分隔線===== '
             '那種在棒球版是大師但在遊戲版是廢文王的情況=====分隔線===== '
             '也是很常見，所以使用者名稱搭配文章發表版面會是一組可能=====分隔線===== 不錯的特徵',
 'url': 'https://www.ptt.cc/bbs/DataScience/M.1612527945.A.1FE.html'}
Traceback (most recent call last):
  File "c:\users\user\anaconda3\envs\crawler\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\user\anaconda3\envs\crawler\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\User\Desktop\AI大數據\Jupyterlab\Day029\Day029\pipelines.py", line 44, in process_item
    self.conn.execute(sql,x)
sqlite3.OperationalError: no such table: fastfood_ptt
2021-03-03 19:11:59 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-03 19:11:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1227,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 7346,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/404': 1,
 'dupefilter/filtered': 44,
 'elapsed_time_seconds': 1.739263,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 3, 11, 11, 59, 319666),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 3,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2021, 3, 3, 11, 11, 57, 580403)}
2021-03-03 19:11:59 [scrapy.core.engine] INFO: Spider closed (finished)
